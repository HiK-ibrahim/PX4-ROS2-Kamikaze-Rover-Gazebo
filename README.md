# PX4-ROS2-Kamikaze-Rover-Gazebo

An autonomous **red-target tracking (Kamikaze)** system for differential rovers using **PX4 Autopilot**, **ROS 2**, **Gazebo**, and **OpenCV**.

---

## ğŸ“Œ Project Overview

This project demonstrates a modular **"Kamikaze" mission** where a ground rover autonomously detects a **red buoy** in a Gazebo simulation and aggressively intercepts it at high speed.

The system follows a **decoupled architecture**, separating:

* **Perception (Vision)**
* **Control (Actuation)**

into independent **ROS 2 nodes**, ensuring scalability, testability, and modularity.

---

## ğŸ§° Technical Stack

| Component          | Technology                 |
| ------------------ | -------------------------- |
| Autopilot          | PX4 Autopilot (v1.14+)     |
| Middleware         | Micro XRCE-DDS Agent       |
| Simulation         | Gazebo (Garden / Harmonic) |
| Robotics Framework | ROS 2 (Humble)             |
| Vision             | OpenCV (Python)            |

---

## ğŸ§  System Architecture & Communication

The system uses a **Publish / Subscribe** communication model.

### ğŸ” Vision Node (Perception)

* Subscribes to:

  ```
  /front_camera/image
  ```
* Source: Gazebo camera via ROSâ€“Gazebo bridge
* Processing:

  * HSV color masking
  * Red object detection
  * Target centroid extraction
* Publishes:

  ```
  /vision/target_info
  ```

---

### ğŸ® Controller Node (Actuation)

* Subscribes to:

  ```
  /vision/target_info
  ```
* Computes:

  * Horizontal steering error
  * Proportional control law
* Publishes to PX4:

  ```
  /fmu/in/manual_control_input
  ```
* Message type:

  ```
  px4_msgs/msg/ManualControlSetpoint
  ```

---

## ğŸ—ï¸ Node Interaction Diagram

```
Gazebo Camera
      â”‚
      â–¼
/front_camera/image
      â”‚
      â–¼
Vision Node (OpenCV)
      â”‚
      â–¼
/vision/target_info
      â”‚
      â–¼
Controller Node (P-Control)
      â”‚
      â–¼
/fmu/in/manual_control_input
      â”‚
      â–¼
PX4 Rover Controller
```

---

## ğŸš€ Execution Guide

To run the mission, open **5 separate terminals** and execute the following steps **in order**.

---

### 1ï¸âƒ£ PX4 SITL & Gazebo

```bash
cd ~/PX4-Autopilot
PX4_GZ_WORLD=baylands make px4_sitl gz_rover_differential
```

---

### 2ï¸âƒ£ Micro XRCE-DDS Agent

```bash
MicroXRCEAgent udp4 -p 8888
```

---

### 3ï¸âƒ£ ROSâ€“Gazebo Bridge (Camera)

```bash
ros2 run ros_gz_bridge parameter_bridge \
/front_camera/image@sensor_msgs/msg/Image@gz.msgs.Image
```

---

### 4ï¸âƒ£ Vision Node (Perception)

```bash
python3 vision_node.py
```

---

### 5ï¸âƒ£ Controller Node (Action)

```bash
python3 controller_node.py
```

---

## ğŸ‡¹ğŸ‡· TÃ¼rkÃ§e AÃ§Ä±klama

### Proje Ã–zeti

Bu proje, Gazebo simÃ¼lasyon ortamÄ±nda Ã§alÄ±ÅŸan diferansiyel sÃ¼rÃ¼ÅŸlÃ¼ bir rover'Ä±n **kÄ±rmÄ±zÄ± bir dubayÄ± otonom olarak tespit etmesini** ve **yÃ¼ksek hÄ±zla hedefe yÃ¶nelmesini (Kamikaze gÃ¶revi)** amaÃ§lamaktadÄ±r.

Sistem, **AlgÄ±lama (GÃ¶rÃ¼ntÃ¼ Ä°ÅŸleme)** ve **Kontrol (Hareket)** bileÅŸenlerini birbirinden baÄŸÄ±msÄ±z **ROS 2 dÃ¼ÄŸÃ¼mleri** olarak tasarlayan **modÃ¼ler bir mimariye** sahiptir.

---

### Teknik AltyapÄ±

* **Otopilot:** PX4 Autopilot
* **HaberleÅŸme:** Micro XRCE-DDS Agent
* **SimÃ¼lasyon:** Gazebo
* **Robotik Framework:** ROS 2 (Humble)
* **GÃ¶rÃ¼ntÃ¼ Ä°ÅŸleme:** Python & OpenCV

---

### Sistem Mimarisi

* **Vision Node (AlgÄ±lama):**

  * `/front_camera/image` topic'inden gÃ¶rÃ¼ntÃ¼yÃ¼ alÄ±r
  * HSV maskeleme ile kÄ±rmÄ±zÄ± hedefi tespit eder
  * Hedef koordinatlarÄ±nÄ± `/vision/target_info` topic'ine yayÄ±nlar

* **Controller Node (Kontrol):**

  * Hedef koordinatlarÄ±nÄ± dinler
  * Sapma (hata) hesabÄ± yapar
  * PX4'Ã¼n anlayacaÄŸÄ± `ManualControlSetpoint` mesajÄ±nÄ± Ã¼retir

---
---

## âœ¨ Author

**Ä°brahim KÃ¶se**
PX4 Â· ROS 2 Â· Autonomous Systems
